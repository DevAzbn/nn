import tensorflow as tf
import json
#from keras.models import load_model
#from keras.models import model_from_json
#from keras.models import model_from_yaml

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
	tf.keras.layers.Flatten(),
	tf.keras.layers.Dense(512, activation=tf.nn.relu),
	tf.keras.layers.Dropout(0.2),
	tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)
model.evaluate(x_test, y_test)


###https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model###

#full save
#model.save('tf.h5');
#model = load_model('my_model.h5')

#weights save
model.save_weights('tf_weights.h5')
#load weights
#model.load_weights('tf_weights.h5')
#model.load_weights('tf_weights.h5', by_name=True)

model_json = model.to_json()
with open('tf.json', 'w') as f:
	#json.dump(model_json, f)
	f.write(model_json)

#with open('tf.txt') as f:
#	data = json.loads(f)

#model_json = model.to_json()
#model = model_from_json(json_string)
#model_yaml = model.to_yaml()
#model = model_from_yaml(yaml_string)

###------------------------------------------------------------------###

del model



pip install -r requirements.txt

python -m pip install --upgrade pip
pip install --upgrade
pip list -o
for i in $(pip list -o | awk 'NR > 2 {print $1}'); do sudo pip install -U $i; done


import subprocess as sbp
import pip
pkgs = eval(str(sbp.run("pip3 list -o --format=json", shell=True, stdout=sbp.PIPE).stdout, encoding='utf-8'))
for pkg in pkgs:
	sbp.run("pip3 install --upgrade " + pkg['name'], shell=True)